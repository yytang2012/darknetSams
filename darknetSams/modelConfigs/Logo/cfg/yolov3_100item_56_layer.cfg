[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=96
# subdivisions=4
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=3
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 1500200
policy=steps
steps= 50000, 100000, 300000, 500000 
scales= .5, .2, .5, .2

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

## the layer to revise --
# the 1st resnet block for 208 x 208
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# the 1st resnet block for 104 x 104
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# # the 2nd resnet block for the 104 x 104
# [convolutional]
# batch_normalize=1
# filters=32
# size=1
# stride=1
# pad=1
# activation=leaky

# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=leaky

# [shortcut]
# from=-3
# activation=linear


# the 1st resnet block for 52 x 52
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 2nd resnet block for 52 x 52
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# the 3rd resnet block for 52 x 52
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# the 4th resnet block for 52 x 52
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 1st resnet block for 26 x 26
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# the 2nd resnet block for 26 x 26
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 3rd resnet block for 26 x 26
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 4th resnet block for 26 x 26
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 1nd resnet block for 13 x 13
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 2nd resnet block for 13 x 13
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


# the 3rd resnet block for 13 x 13
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear



[convolutional]
batch_normalize=1
filters=384
size=1
stride=1
pad=1
activation=leaky


[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

###########

# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=leaky

# [convolutional]
# batch_normalize=1
# filters=512
# size=3
# stride=1
# pad=1
# activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=108
activation=linear


[yolo]
mask = 3,4,5
anchors = 46, 42, 119, 52,  67,107, 176, 98, 121,160, 229,216
classes=31
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 34

[convolutional]
batch_normalize=1
filters=192
size=1
stride=1
pad=1
activation=leaky
 
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky


# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=leaky
 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=108
activation=linear

[yolo]
mask = 0,1,2
anchors = 46, 42, 119, 52,  67,107, 176, 98, 121,160, 229,216
classes=31
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1